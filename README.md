# MRI_AI_Diagnosis: Sistema de soporte al diagnÃ³stico de trastornos neurolÃ³gicos mediante MRI

![DiagnÃ³stico IA MRI](https://img.shields.io/badge/Estado-Finalizado-green)
![Python 3.9+](https://img.shields.io/badge/Python-3.9%2B-blue)
![Licencia](https://img.shields.io/github/license/xavipallas/MRI_AI_Diagnosis)
![Dependencias](https://img.shields.io/badge/Dependencias-Pipfile-green)

---

## ğŸš€ VisiÃ³n general del proyecto

`MRI_AI_Diagnosis` es un sistema integral diseÃ±ado para asistir en el diagnÃ³stico de trastornos neurolÃ³gicos (Alzheimer y Parkinson) a partir de imÃ¡genes de Resonancia MagnÃ©tica (MRI). El proyecto utiliza una combinaciÃ³n de **segmentaciÃ³n de imÃ¡genes mÃ©dicas con redes neuronales UNet** y **clasificaciÃ³n basada en caracterÃ­sticas con XGBoost**, todo orquestado a travÃ©s de una **interfaz grÃ¡fica de usuario (GUI) interactiva con Streamlit**.

### CaracterÃ­sticas principales:

* **Preprocesamiento de MRI:** ConversiÃ³n de DICOM a NIfTI, registro y normalizaciÃ³n de imÃ¡genes cerebrales.
* **SegmentaciÃ³n multitarea:** Un modelo UNet 3D entrenado para segmentar simultÃ¡neamente regiones clave del cerebro (hipocampos y putÃ¡menes) en las MRIs.
* **ExtracciÃ³n de caracterÃ­sticas cuantitativas:** CÃ¡lculo automÃ¡tico de volÃºmenes, caracterÃ­sticas de forma y textura a partir de las regiones segmentadas.
* **ClasificaciÃ³n avanzada:** Un clasificador XGBoost entrenado con las caracterÃ­sticas extraÃ­das para predecir la condiciÃ³n del paciente (Alzheimer, Parkinson, Control).
* **Interfaz de usuario intuitiva:** Una aplicaciÃ³n Streamlit que permite cargar imÃ¡genes MRI, realizar la segmentaciÃ³n y clasificaciÃ³n, y visualizar los resultados de manera interactiva.

---

## ğŸ› ï¸ Estructura del proyecto

El repositorio estÃ¡ organizado de forma modular para facilitar la navegaciÃ³n, el desarrollo y el mantenimiento:

```
MRI_AI_Diagnosis/
â”œâ”€â”€ .github/                      # Configuraciones de GitHub (ej. workflows de CI/CD)
â”œâ”€â”€ data/                         # Almacena datos de ejemplo y plantillas
â”‚   â”œâ”€â”€ raw_dicom_example/        # Ejemplos de MRIs en series DICOM
â”‚   â”œâ”€â”€ registered_nifti_example/ # Ejemplos de MRIs registradas (salida del preprocesamiento)
â”‚   â”œâ”€â”€ segmentation_masks_template/ # MÃ¡scaras de plantilla MNI y la plantilla de referencia
â”‚   â”œâ”€â”€ processed_segmentation_masks/ # MÃ¡scaras de segmentaciÃ³n de MRIs
â”‚   â””â”€â”€ transform_summary.json    # RelaciÃ³n de transformaciÃ³n y condiciÃ³n de las MRIs registradas
â”œâ”€â”€ models/                       # Modelos entrenados
â”‚   â”œâ”€â”€ unet_multitask.pth        # Modelo UNet de segmentaciÃ³n
â”‚   â””â”€â”€ xgboost_classifier.joblib # Clasificador XGBoost
â”œâ”€â”€ notebooks/                    # Cuadernos Jupyter para exploraciÃ³n, tutoriales y experimentaciÃ³n
â”œâ”€â”€ src/                          # CÃ³digo fuente modular del proyecto
â”‚   â”œâ”€â”€ config.py                 # Configuraciones globales y constantes
â”‚   â”œâ”€â”€ data_processing/          # Scripts para preprocesamiento y carga de datos
â”‚   â”‚   â”œâ”€â”€ dicom_to_nifti.py     # ConversiÃ³n de DICOM a NIfTI y registro rÃ­gido
â”‚   â”‚   â”œâ”€â”€ ants_registration.py  # Registro de mÃ¡scaras ANTs
â”‚   â”‚   â””â”€â”€ data_loader.py        # Clases Dataset y funciones de carga de datos
â”‚   â”œâ”€â”€ segmentation/             # MÃ³dulos relacionados con la segmentaciÃ³n UNet
â”‚   â”‚   â”œâ”€â”€ unet_architecture.py  # DefiniciÃ³n de la arquitectura UNet
â”‚   â”‚   â”œâ”€â”€ unet_trainer.py       # LÃ³gica de entrenamiento del UNet
â”‚   â”‚   â””â”€â”€ unet_inference.py     # LÃ³gica para la inferencia con el UNet
â”‚   â”œâ”€â”€ classification/           # MÃ³dulos para extracciÃ³n de caracterÃ­sticas y clasificaciÃ³n
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py # Funciones para extraer caracterÃ­sticas de volumen, forma y textura
â”‚   â”‚   â””â”€â”€ classifier_model.py   # Entrenamiento y carga del clasificador XGBoost
â”‚   â”œâ”€â”€ visualization/            # Scripts para visualizaciÃ³n de MRIs y mÃ¡scaras
â”‚   â”‚   â”œâ”€â”€ plot_mris.py
â”‚   â”‚   â””â”€â”€ plot_mris_with_masks.py
â”‚   â””â”€â”€ gui/                      # MÃ³dulo para la interfaz de usuario Streamlit
â”‚       â””â”€â”€ app.py                # AplicaciÃ³n Streamlit principal
â”œâ”€â”€ .gitignore                    # Archivos y directorios ignorados por Git
â”œâ”€â”€ LICENSE                       # InformaciÃ³n de licencia
â”œâ”€â”€ README.md                     # Este archivo
â””â”€â”€ requirements.txt              # Dependencias del proyecto
```

---

## âš™ï¸ InstalaciÃ³n

Sigue estos pasos para configurar el entorno y ejecutar el proyecto localmente.

### 1. Clona el repositorio

```
git clone [https://github.com/xavipallas/MRI_AI_Diagnosis.git](https://github.com/xavipallas/MRI_AI_Diagnosis.git)
cd MRI_AI_Diagnosis
```

### 2. Crea y activa el entorno virtual

```
python -m venv venv
```

* **En Windows:**

  ```
  .\venv\Scripts\activate
  ```
  (Si tienes problemas con la polÃ­tica de ejecuciÃ³n de PowerShell, puedes necesitar ejecutar Set-ExecutionPolicy          RemoteSigned como administrador una vez).
  
* **En macOS/Linux:**
  ```
  source venv/bin/activate
  ```

### 3. Instala las dependencias
Con tu entorno virtual activado, instala todas las librerÃ­as necesarias:
```
pip install -r requirements.txt
```

---

## ğŸš€ Uso
El proyecto puede usarse de varias maneras: a travÃ©s de su GUI interactiva, o ejecutando scripts individuales para cada etapa del pipeline.

### 1. Ejecutar la Interfaz GrÃ¡fica de Usuario (GUI)
La forma mÃ¡s sencilla de interactuar con el sistema es a travÃ©s de la aplicaciÃ³n Streamlit.

```
streamlit run src/gui/app.py
```
Esto abrirÃ¡ la aplicaciÃ³n en tu navegador web, donde podrÃ¡s cargar tus archivos MRI y obtener resultados.

### 2. Ejecutar Scripts individuales (Modo Desarrollo/Prueba)
Si deseas ejecutar etapas especÃ­ficas del pipeline o realizar un entrenamiento completo, puedes llamar directamente a los scripts. AsegÃºrate de estar en la raÃ­z del proyecto (MRI_AI_Diagnosis) y con tu entorno virtual activado.

* **Ejemplo de Preprocesamiento DICOM a NIfTI:**
    ```
    python src/data_processing/dicom_to_nifti.py
    ```
    (AsegÃºrate de ajustar las rutas de entrada/salida dentro del if __name__ == "__main__": del script o pasarlas como argumentos si el script lo soporta).

* **Ejemplo de Registro de mÃ¡scaras (ANTs):**
    ```
    python src/data_processing/ants_registration.py
    ```
* **Ejemplo de Entrenamiento del UNet:**
    ```
    python src/segmentation/unet_trainer.py
    ```
    (Este script espera que tus datos estÃ©n preparados en las rutas definidas en src/config.py y que la carga de datos funcione).

* **Ejemplo de ExtracciÃ³n de caracterÃ­sticas y clasificaciÃ³n (Pipeline Completo):**
    Para ejecutar el pipeline completo de entrenamiento y evaluaciÃ³n tal como se describe en el script original (asumiendo que estÃ¡ actualizado para usar los nuevos mÃ³dulos), puedes usar el siguiente script `src/main_pipeline.py`.
    ```Python
    # src/main_pipeline.py
    from src.data_processing.data_loader import load_all_data, MultitaskSegmentationDataset, FeatureExtractionDataset, IMAGE_TRANSFORMS
    from src.segmentation.unet_architecture import build_unet_multitask
    from src.segmentation.unet_trainer import train_unet
    from src.segmentation.unet_inference import load_unet_model
    from src.classification.feature_extraction import extract_features
    from src.classification.classifier_model import train_and_evaluate_xgboost, load_xgboost_classifier
    from src.config import DATA_DIR, MASKS_DIR, REGIONS, DEVICE, UNET_MODEL_PATH, XGB_CLASSIFIER_PATH
    from sklearn.model_selection import train_test_split
    from torch.utils.data import DataLoader
    from sklearn.metrics import classification_report
    
    def run_full_pipeline():
        print("Cargando todos los datos...")
        full_data = load_all_data(DATA_DIR, MASKS_DIR)

    train_data, temp_data = train_test_split(
        full_data, test_size=0.30, stratify=[d['label'] for d in full_data], random_state=42
    )
    val_data, test_data = train_test_split(
        temp_data, test_size=0.5, stratify=[d['label'] for d in temp_data], random_state=42
    )

    # 1. Entrenamiento de la U-Net (si no estÃ¡ ya entrenada)
    train_ds = MultitaskSegmentationDataset(train_data, transform=IMAGE_TRANSFORMS)
    val_ds = MultitaskSegmentationDataset(val_data, transform=IMAGE_TRANSFORMS)
    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=2)

    unet_model = build_unet_multitask(len(REGIONS), DEVICE)
    print("ğŸš€ Entrenando U-Net multitarea para segmentaciÃ³n...")
    train_unet(unet_model, train_loader, val_loader)

    # 2. Cargar el UNet (si ya estÃ¡ entrenado o despuÃ©s de entrenar)
    print("Cargando el modelo UNet...")
    trained_unet_model = load_unet_model() # Carga desde UNET_MODEL_PATH

    # 3. ExtracciÃ³n de caracterÃ­sticas
    print("ğŸ’ª Extrayendo caracterÃ­sticas para clasificaciÃ³n...")
    feature_ds = FeatureExtractionDataset(full_data, transform=IMAGE_TRANSFORMS)
    X_features, y_labels = extract_features(trained_unet_model, feature_ds)

    # 4. Entrenamiento y evaluaciÃ³n de XGBoost
    print("\nğŸ”¬ Entrenando y evaluando XGBoostClassifier...")
    best_xgb_model = train_and_evaluate_xgboost(X_features, y_labels) # GuardarÃ¡ el modelo

    # 5. Reporte final
    y_pred_final = best_xgb_model.predict(X_features)
    print("\n--- Reporte de ClasificaciÃ³n Final (XGBoost sobre el conjunto completo de caracterÃ­sticas) ---")
    print(classification_report(y_labels, y_pred_final, digits=4))

    if __name__ == "__main__":
        run_full_pipeline()
    ```
    Puedes guardar este cÃ³digo como `src/main_pipeline.py` y ejecutarlo con:
    
    ```
    python src/main_pipeline.py
    ```

---

## ğŸ“‚ Datos de ejemplo
Para facilitar el testing y la comprensiÃ³n del proyecto, se incluyen pequeÃ±os conjuntos de datos de ejemplo en la carpeta `data/`:

* `data/raw_dicom_example/`: Una estructura mÃ­nima de carpetas que simula un dataset DICOM real.
* `data/registered_nifti_example/`: MRIs de ejemplo que han pasado por la etapa de preprocesamiento y registro.
* `data/segmentation_masks_template/`: MÃ¡scaras de segmentaciÃ³n cerebrales de un atlas (ej. MNI) utilizadas como referencia para el registro espacial.

---

## ğŸ“ Licencia
Este proyecto estÃ¡ distribuido bajo la MIT License. Puedes encontrar los detalles completos en el archivo `LICENSE`.
