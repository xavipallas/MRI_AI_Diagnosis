# src/gui/app.py
import streamlit as st
import nibabel as nib
import numpy as np
import os
from pathlib import Path
import pandas as pd
import torch
import tempfile # Para manejar archivos temporales

from src.config import DEVICE, REGIONS, UNET_MODEL_PATH, XGB_CLASSIFIER_PATH, IMAGE_SIZE
from src.segmentation.unet_inference import load_unet_model
from src.classification.feature_extraction import extract_region_volumes, extract_shape_features, extract_texture_features
from src.classification.classifier_model import load_xgboost_classifier
from monai.transforms import (
    Compose, EnsureChannelFirst, LoadImage, Resize, ScaleIntensity, ToTensor
)

# Mapping para el nombre completo de las regiones (para visualizaci칩n de importancias)
REGION_FULL_NAMES = {
    "left_hippocampus": "Hipocampo Izquierdo",
    "right_hippocampus": "Hipocampo Derecho",
    "left_putamen": "Putamen Izquierdo",
    "right_putamen": "Putamen Derecho"
}

INFERENCE_TRANSFORMS_GUI = Compose([
    LoadImage(image_only=True),
    EnsureChannelFirst(),
    ScaleIntensity(),
    Resize(spatial_size=IMAGE_SIZE),
    ToTensor()
])

# Carga los modelos al inicio de la aplicaci칩n para que no se recarguen con cada interacci칩n
@st.cache_resource # Esto es importante para Streamlit y modelos grandes
def cached_load_models():
    unet = load_unet_model()
    xgb_classifier = load_xgboost_classifier()
    return unet, xgb_classifier

unet_model, xgb_classifier = cached_load_models()

# --- Funciones de Preprocesamiento y Segmentaci칩n ---
def preprocess_mri(nifti_data: np.ndarray) -> torch.Tensor:
    """
    Aplica las transformaciones definidas a los datos NIfTI de una MRI.
    Asegura que los datos est칠n en el formato correcto para el modelo UNet.

    Args:
        nifti_data (np.ndarray): Datos de la imagen MRI cargados de un archivo NIfTI.

    Returns:
        torch.Tensor: El tensor de la imagen MRI preprocesada, listo para la entrada al modelo.
    """
    # EnsureChannelFirst: a침ade la dimensi칩n de canal (1, D, H, W)
    # MONAI espera (C, D, H, W) para im치genes 3D
    data_with_channel = np.expand_dims(nifti_data, axis=0) 

    # ScaleIntensity: normaliza al rango [0, 1] o similar
    min_val, max_val = data_with_channel.min(), data_with_channel.max()
    if max_val - min_val > 0:
        scaled_data = (data_with_channel - min_val) / (max_val - min_val)
    else:
        # Manejar el caso de una imagen constante para evitar divisi칩n por cero
        scaled_data = np.zeros_like(data_with_channel) 

    # Convertir a tensor de PyTorch antes de Resize
    input_tensor = torch.from_numpy(scaled_data).float()

    # Resize: a (96, 96, 96)
    # Asegurarse de que esta transformaci칩n se aplica a un tensor.
    resized_tensor = Resize(spatial_size=(96, 96, 96))(input_tensor)

    # ToTensor: ya es un tensor, por lo que este paso es esencialmente una no-operaci칩n aqu칤
    return resized_tensor


# --- Funciones de Extracci칩n de Caracter칤sticas ---
def get_feature_names() -> list[str]:
    """
    Genera los nombres de las caracter칤sticas en el orden en que son extra칤das.
    Necesario para interpretar la importancia de las caracter칤sticas del XGBoost.

    Returns:
        list[str]: Una lista de cadenas con los nombres de las caracter칤sticas.
    """
    feature_names = []
    for region in REGIONS:
        full_region_name = REGION_FULL_NAMES.get(region, region)
        feature_names.append(f"{full_region_name} - Volumen")
        feature_names.extend([
            f"{full_region_name} - 츼rea 2D",
            f"{full_region_name} - Excentricidad",
            f"{full_region_name} - Solidez"
            f"{full_region_name} - Contraste",
            f"{full_region_name} - Homogeneidad",
            f"{full_region_name} - Energ칤a",
            f"{full_region_name} - Correlaci칩n"
        ])
    return feature_names

# --- Datos de referencia hipot칠ticos para la explicaci칩n cl칤nica ---
# Estos datos deber칤an ser obtenidos de un conjunto de datos de entrenamiento representativo
# y validados cl칤nicamente para un uso real. Aqu칤 son solo para demostraci칩n.
def generate_mock_reference_ranges(feature_names, regions):
    """
    Genera rangos de referencia hipot칠ticos para varias caracter칤sticas
    para las clases 'Alzheimer', 'Parkinson' y 'Control'.
    Estos datos son solo para fines de demostraci칩n y no son m칠dicamente precisos.

    Args:
        feature_names (list[str]): Nombres de las caracter칤sticas.
        regions (list[str]): Nombres de las regiones de inter칠s.

    Returns:
        dict: Un diccionario anidado con los rangos de referencia (media, desviaci칩n est치ndar)
              para cada caracter칤stica y clase.
    """
    mock_ranges = {
        "Alzheimer": {},
        "Parkinson": {},
        "Control": {}
    }

    # Valores base para Control (saludable)
    base_control_volumes = {
        "left_hippocampus": 1400, "right_hippocampus": 1450,
        "left_putamen": 1800, "right_putamen": 1850
    }
    base_control_area_2d = 200
    base_control_eccentricity = 0.7
    base_control_solidity = 0.95
    base_control_contrast = 0.08
    base_control_homogeneity = 0.98
    base_control_energy = 0.85
    base_control_correlation = 0.95

    for feature_name in feature_names:
        # Determinar tipo de caracter칤stica y regi칩n
        parts = feature_name.split(' - ')
        region_full_name = parts[0]
        feature_type = parts[1]
        
        region_key = next(k for k, v in REGION_FULL_NAMES.items() if v == region_full_name)

        # Control
        if "Volumen" in feature_type:
            mean_c = base_control_volumes[region_key]
            std_c = mean_c * 0.07 # 7% std dev
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            # Alzheimer: vol칰menes m치s peque침os (ej., 25% de reducci칩n para hipocampo, 10% para putamen)
            mean_a = mean_c * 0.75 if "hippocampus" in region_key else mean_c * 0.9
            std_a = std_c * 1.2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            # Parkinson: el putamen podr칤a estar m치s afectado, el hipocampo menos que en Alzheimer
            mean_p = mean_c * 0.95 if "hippocampus" in region_key else mean_c * 0.85
            std_p = std_c * 1.1
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "츼rea 2D" in feature_type:
            mean_c = base_control_area_2d
            std_c = mean_c * 0.1
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 0.75
            std_a = std_c * 1.2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 0.9
            std_p = std_c * 1.1
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Excentricidad" in feature_type: # Mayor para formas m치s alargadas
            mean_c = base_control_eccentricity
            std_c = 0.03
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 1.2 # M치s exc칠ntrico para Alzheimer (m치s alargado)
            std_a = std_c * 1.5
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 1.05 # Ligeramente m치s exc칠ntrico para Parkinson
            std_p = std_c * 1.2
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Solidez" in feature_type: # Menor para formas m치s irregulares
            mean_c = base_control_solidity
            std_c = 0.01
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 0.9 # Menos s칩lido para Alzheimer (m치s irregular)
            std_a = std_c * 2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 0.95 # Ligeramente menos s칩lido para Parkinson
            std_p = std_c * 1.5
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Contraste" in feature_type: # Mayor para tejido m치s heterog칠neo
            mean_c = base_control_contrast
            std_c = 0.01
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 1.5 # Mayor contraste para Alzheimer (m치s heterogeneidad)
            std_a = std_c * 2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 1.2
            std_p = std_c * 1.5
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Homogeneidad" in feature_type: # Menor para tejido menos uniforme
            mean_c = base_control_homogeneity
            std_c = 0.005
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 0.8 # Menor homogeneidad para Alzheimer
            std_a = std_c * 2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 0.9
            std_p = std_c * 1.5
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Energ칤a" in feature_type: # Menor para tejido menos uniforme
            mean_c = base_control_energy
            std_c = 0.03
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 0.7 # Menor energ칤a para Alzheimer
            std_a = std_c * 2
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 0.8
            std_p = std_c * 1.5
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
        elif "Correlaci칩n" in feature_type: # Menor para patrones menos estructurados
            mean_c = base_control_correlation
            std_c = 0.02
            mock_ranges["Control"][feature_name] = (mean_c, std_c)
            mean_a = mean_c * 0.8 # Menor correlaci칩n para Alzheimer
            std_a = std_c * 1.5
            mock_ranges["Alzheimer"][feature_name] = (mean_a, std_a)
            mean_p = mean_c * 0.9
            std_p = std_c * 1.2
            mock_ranges["Parkinson"][feature_name] = (mean_p, std_p)
    return mock_ranges

HYPOTHETICAL_REFERENCE_RANGES = generate_mock_reference_ranges(get_feature_names(), REGIONS)


# --- GUI - Dise침o y L칩gica con Streamlit ---

st.set_page_config(
    page_title="MRI AI",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("游 Herramienta de soporte al diagn칩stico de RM Cerebral")
st.markdown("---")

# Cargar modelos una sola vez al inicio de la aplicaci칩n
# Aseg칰rate de que estas rutas son correctas y los archivos existen.
unet_model_path = Path("unet_multitask.pth") 
xgb_classifier_path = Path("xgboost_classifier.joblib") 

unet_model = load_unet_model(len(REGIONS), DEVICE, unet_model_path)
xgb_classifier = load_xgboost_classifier(xgb_classifier_path)

# Mapeo de etiquetas num칠ricas a nombres legibles
CLASS_LABELS = {0: "Alzheimer", 1: "Parkinson", 2: "Control"}
FEATURE_NAMES = get_feature_names()

# Secci칩n para subir archivo en la barra lateral
with st.sidebar:
    st.header("Cargar MRI del Paciente")
    uploaded_file = st.file_uploader(
        "Sube un archivo NIfTI (.nii o .nii.gz) de MRI:", type=["nii", "nii.gz"]
    )

# Secci칩n principal para visualizaci칩n y resultados
col1, col2 = st.columns([0.6, 0.4])

with col1:
    st.header("Visualizaci칩n de la MRI")
    if uploaded_file is not None:
        temp_file_path = None # Inicializar a None

        try:
            # Leer el archivo NIfTI
            bytes_data = uploaded_file.getvalue()
            # Crear un archivo temporal para nibabel
            with tempfile.NamedTemporaryFile(delete=False, suffix=".nii.gz") as tmp_file:
                tmp_file.write(bytes_data)
                temp_file_path = Path(tmp_file.name) # Guardar la ruta del archivo temporal

            mri_img = nib.load(temp_file_path)
            mri_data_original = mri_img.get_fdata()

            # Almacenar los datos originales en session_state para persistencia y navegaci칩n
            st.session_state['mri_data_original'] = mri_data_original

            # Generar y mostrar ID del paciente desde el nombre del archivo
            # Solo generar nuevo ID si el archivo subido es diferente al anterior
            if 'patient_id' not in st.session_state or st.session_state.get('last_uploaded_file_name') != uploaded_file.name:
                st.session_state['patient_id'] = Path(uploaded_file.name).stem # Usar el nombre del archivo como ID
                st.session_state['last_uploaded_file_name'] = uploaded_file.name # Rastrear el 칰ltimo archivo subido
                # Resetear la clasificaci칩n si se sube un nuevo archivo
                st.session_state.pop('predicted_label', None)
                st.session_state.pop('extracted_features', None)
                st.session_state.pop('prediction_probs', None)
                st.session_state.pop('segmented_masks_tensor', None) # Limpiar m치scaras anteriores
                # Resetear el 칤ndice de corte a la mitad si es un nuevo archivo
                st.session_state['current_slice_idx'] = mri_data_original.shape[2] // 2


            st.subheader(f"MRI cargada para ID: **{st.session_state['patient_id']}**")

            # Inicializar el 칤ndice de corte si no est치 ya en session_state
            if 'current_slice_idx' not in st.session_state:
                st.session_state['current_slice_idx'] = mri_data_original.shape[2] // 2

            # 칈ndice m치ximo del corte
            max_slice_idx = mri_data_original.shape[2] - 1

            # Funciones para sincronizar el slider y el number_input
            def update_slice_from_slider():
                st.session_state['current_slice_idx'] = st.session_state['slice_slider_key']

            def update_slice_from_number_input():
                st.session_state['current_slice_idx'] = st.session_state['slice_number_input_key']
            
            # Crear columnas para el textbox y el slider
            slice_col1, slice_col2 = st.columns(2)

            with slice_col1:
                # Entrada num칠rica para el corte
                st.number_input(
                    "N칰mero de Corte Axial",
                    min_value=0,
                    max_value=max_slice_idx,
                    value=st.session_state['current_slice_idx'],
                    key="slice_number_input_key",
                    on_change=update_slice_from_number_input,
                    help="Introduce el n칰mero de corte axial para visualizar."
                )
            with slice_col2:
                # Slider para navegar por los cortes
                st.slider(
                    "Seleccionar Corte Axial",
                    0,
                    max_slice_idx,
                    value=st.session_state['current_slice_idx'],
                    key="slice_slider_key",
                    on_change=update_slice_from_slider,
                    help="Usa el slider para navegar a trav칠s de los cortes axiales."
                )
            
            # El 칤ndice de corte a mostrar es el que est치 en session_state
            slice_idx_to_display = st.session_state['current_slice_idx']

            # Preparar corte para visualizaci칩n basada en el slider/number_input
            mri_slice_display = mri_data_original[:, :, slice_idx_to_display]

            # Normalizar para visualizaci칩n
            mri_slice_display = (mri_slice_display - mri_slice_display.min()) / (mri_slice_display.max() - mri_slice_display.min() + 1e-8)
            
            # Usar use_container_width en lugar de use_column_width
            st.image(np.rot90(mri_slice_display), caption=f"MRI Original (Corte Axial {slice_idx_to_display + 1}/{mri_data_original.shape[2]})", use_container_width=True)

            st.header("Resultados de la clasificaci칩n")
            
            # --- Clasificaci칩n Autom치tica ---
            # Solo clasificar si no se ha clasificado ya para este archivo
            if 'predicted_label' not in st.session_state:
                with st.spinner("Procesando y clasificando autom치ticamente... Esto puede tomar un momento."):
                    # Preprocesar la MRI para el UNet
                    preprocessed_mri_tensor = preprocess_mri(mri_data_original)

                    # Realizar segmentaci칩n
                    segmented_masks_tensor = perform_segmentation(unet_model, preprocessed_mri_tensor)
                    st.session_state['segmented_masks_tensor'] = segmented_masks_tensor # Almacenar m치scaras segmentadas

                    # Extraer caracter칤sticas
                    volumes = extract_region_volumes(segmented_masks_tensor)
                    shape_features = extract_shape_features(segmented_masks_tensor)
                    texture_features = extract_texture_features(segmented_masks_tensor)
                    
                    extracted_features = np.array(volumes + shape_features + texture_features).reshape(1, -1)

                    # Clasificar con XGBoost
                    prediction_probs = xgb_classifier.predict_proba(extracted_features)[0]
                    predicted_class_idx = np.argmax(prediction_probs)
                    predicted_label = CLASS_LABELS[predicted_class_idx]

                    # Guardar resultados en st.session_state para la explicaci칩n
                    st.session_state['predicted_label'] = predicted_label
                    st.session_state['prediction_probs'] = prediction_probs
                    st.session_state['extracted_features'] = extracted_features[0] # Almacenar como 1D array
                    # El ID del paciente ya est치 en session_state
            
            # Mostrar resultados de clasificaci칩n (ya sea autom치tica o de una sesi칩n anterior)
            if 'predicted_label' in st.session_state:
                current_patient_id = st.session_state.get('patient_id', 'N/A')
                predicted_label = st.session_state['predicted_label']
                prediction_probs = st.session_state['prediction_probs']

                st.markdown(f"## **Diagn칩stico Predicho para ID {current_patient_id}: <span style='color:green;'>{predicted_label}</span>**", unsafe_allow_html=True)
                st.write("Probabilidades de clase:")
                for i, prob in enumerate(prediction_probs):
                    st.write(f"- {CLASS_LABELS[i]}: {prob:.2%}")

        except Exception as e:
            st.error(f"Se produjo un error al procesar el archivo: {e}")
            st.warning("Aseg칰rate de que el archivo es un NIfTI 3D v치lido con las dimensiones esperadas por el modelo.")
            # Limpiar estado si hay un error al procesar el archivo
            st.session_state.pop('mri_data_original', None)
            st.session_state.pop('patient_id', None)
            st.session_state.pop('last_uploaded_file_name', None)
            st.session_state.pop('current_slice_idx', None)
            st.session_state.pop('predicted_label', None)
            st.session_state.pop('extracted_features', None)
            st.session_state.pop('prediction_probs', None)
            st.session_state.pop('segmented_masks_tensor', None)
        finally:
            # Asegurarse de eliminar el archivo temporal incluso si hay un error
            if temp_file_path and temp_file_path.exists():
                os.unlink(temp_file_path)

    else:
        st.info("Por favor, sube un archivo MRI para visualizarlo y clasificarlo.")

with col2:
    st.header("Explicaci칩n del modelo")
    # Usar st.session_state para mantener el estado de la predicci칩n y las caracter칤sticas
    if 'predicted_label' in st.session_state and 'extracted_features' in st.session_state:
        predicted_label = st.session_state['predicted_label']
        extracted_features_patient = st.session_state['extracted_features'] # Caracter칤sticas del paciente
        patient_id_display = st.session_state.get('patient_id', 'N/A') # Recuperar ID del paciente
        prediction_probs = st.session_state['prediction_probs'] # Recuperar probabilidades

        st.subheader(f"Explicaci칩n para el diagn칩stico de **{predicted_label}** (ID: {patient_id_display})")

        # Obtener importancias de las caracter칤sticas del clasificador XGBoost
        feature_importances = xgb_classifier.feature_importances_

        # Crear un DataFrame para visualizar mejor las importancias y los valores del paciente
        explanation_df = pd.DataFrame({
            'Caracter칤stica': FEATURE_NAMES,
            'Importancia': feature_importances,
            'Valor del Paciente': extracted_features_patient
        })
        
        # A침adir columnas para los rangos de referencia
        explanation_df['Rango T칤pico (Control)'] = explanation_df['Caracter칤stica'].apply(
            lambda x: f"{HYPOTHETICAL_REFERENCE_RANGES['Control'][x][0]:.2f} 췀 {HYPOTHETICAL_REFERENCE_RANGES['Control'][x][1]:.2f}"
            if x in HYPOTHETICAL_REFERENCE_RANGES['Control'] else 'N/A'
        )
        explanation_df['Rango T칤pico (Alzheimer)'] = explanation_df['Caracter칤stica'].apply(
            lambda x: f"{HYPOTHETICAL_REFERENCE_RANGES['Alzheimer'][x][0]:.2f} 췀 {HYPOTHETICAL_REFERENCE_RANGES['Alzheimer'][x][1]:.2f}"
            if x in HYPOTHETICAL_REFERENCE_RANGES['Alzheimer'] else 'N/A'
        )
        explanation_df['Rango T칤pico (Parkinson)'] = explanation_df['Caracter칤stica'].apply(
            lambda x: f"{HYPOTHETICAL_REFERENCE_RANGES['Parkinson'][x][0]:.2f} 췀 {HYPOTHETICAL_REFERENCE_RANGES['Parkinson'][x][1]:.2f}"
            if x in HYPOTHETICAL_REFERENCE_RANGES['Parkinson'] else 'N/A'
        )

        # Ordenar por importancia y mostrar las top N
        top_n_features = 10 
        explanation_df = explanation_df.sort_values(by='Importancia', ascending=False).head(top_n_features)

        st.markdown(f"""
        El modelo ha clasificado esta resonancia magn칠tica como **{predicted_label}** con las siguientes probabilidades:
        """)
        for i, prob in enumerate(prediction_probs):
            st.write(f"- {CLASS_LABELS[i]}: {prob:.2%}")

        st.markdown(f"""
        Esta clasificaci칩n se basa en el an치lisis de diversas caracter칤sticas (volumen, forma y textura) extra칤das de regiones cerebrales espec칤ficas.
        A continuaci칩n, se muestran las **{top_n_features} caracter칤sticas que el modelo consider칩 m치s influyentes** para llegar a este diagn칩stico, junto con los valores medidos en la MRI del paciente y rangos de referencia hipot칠ticos para cada clase:
        """)
        st.table(explanation_df)

        st.markdown("""
        **Interpretaci칩n de las caracter칤sticas clave:**
        Los valores de 'Importancia' indican cu치nto contribuy칩 cada caracter칤stica a la decisi칩n final del modelo. Un valor m치s alto significa una mayor influencia. El modelo ha aprendido patrones espec칤ficos en estas caracter칤sticas que se asocian con cada una de las clases (Alzheimer, Parkinson, Control).

        Para cada caracter칤stica listada, puede comparar el **'Valor del Paciente'** con los **'Rangos T칤picos'** de las clases de referencia. Por ejemplo:
        * Si el diagn칩stico predicho es **Alzheimer**, observe si los valores del paciente para caracter칤sticas como el **volumen del hipocampo** son consistentemente **inferiores** a los rangos de control y m치s cercanos a los rangos t칤picos de Alzheimer.
        * Si el diagn칩stico predicho es **Parkinson**, preste atenci칩n a las caracter칤sticas del **putamen**, como su **volumen** o **propiedades de textura**, y c칩mo se comparan con los rangos t칤picos de Parkinson.
        * Para un diagn칩stico de **Control**, los valores del paciente deber칤an estar generalmente dentro de los rangos t칤picos de la poblaci칩n de control.

        Las desviaciones significativas del 'Rango T칤pico (Control)' hacia los rangos de las clases de enfermedad, especialmente para caracter칤sticas con alta 'Importancia', son las que el modelo utiliza como base para su predicci칩n.
        """)

        st.markdown("""
        ### Consideraciones cl칤nicas y validez del modelo:
        Esta herramienta es un **soporte al diagn칩stico** y no debe interpretarse como un diagn칩stico m칠dico definitivo. La validez cl칤nica de este modelo se basa en la calidad y representatividad del conjunto de datos con el que fue entrenado y validado.

        **Para evaluar la validez cl칤nica en este caso espec칤fico, el m칠dico debe considerar:**
        * **Probabilidad de predicci칩n:** Una probabilidad alta para la clase predicha (ej., 90% para Alzheimer) indica una alta confianza del modelo en su clasificaci칩n para este paciente. Probabilidades m치s bajas (ej., 55%) sugieren mayor incertidumbre y requieren una revisi칩n m치s cr칤tica.
        * **Coherencia con la cl칤nica:** Los hallazgos del modelo (caracter칤sticas influyentes y sus valores) deben ser coherentes con la presentaci칩n cl칤nica del paciente, su historial m칠dico y otros resultados de pruebas.
        * **An치lisis de rangos de referencia:** La comparaci칩n de los valores del paciente con los rangos de referencia proporcionados (que idealmente provendr칤an de un estudio poblacional robusto) ayuda a contextualizar las mediciones del paciente. Si los valores del paciente se alinean bien con los patrones conocidos de la enfermedad predicha, esto refuerza la confianza.
        * **Limitaciones del modelo:** Reconozca que los modelos de IA tienen limitaciones y pueden no capturar todas las complejidades biol칩gicas.
        
        La decisi칩n final siempre debe ser tomada por un profesional de la salud cualificado, integrando esta informaci칩n con su juicio cl칤nico experto.
        """)
    else:
        st.info("Sube una MRI para visualizarla y ver la clasificaci칩n y explicaci칩n.")

st.markdown("---")
st.sidebar.markdown("""
    ### Notas:
    * Este prototipo utiliza un modelo de aprendizaje autom치tico para el soporte al diagn칩stico. No debe reemplazar el juicio cl칤nico profesional.
    * Aseg칰rate de que los archivos `unet_multitask.pth` y `xgboost_classifier.joblib` est치n en el mismo directorio que este script.
    * El modelo UNet espera im치genes con un tama침o de (96, 96, 96) despu칠s del preprocesamiento.
""")